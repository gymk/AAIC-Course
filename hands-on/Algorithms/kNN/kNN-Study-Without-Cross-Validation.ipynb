{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours (No Cross Validation or Generalization)\n",
    "\n",
    "Basically trying to implement common distance calculation algorithms and would like to try KNN using those on Iris Data Set.\n",
    "\n",
    "From this trying to observe overfitting/underfitting behaviour when we do not have cross validation\n",
    "\n",
    "Referece\n",
    "    1. [http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/]\n",
    "    2. [https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/cosdist.htm]\n",
    "\n",
    "- Implemented required distance functions (yet to review its accuracy)\n",
    "- Loaded Irsi dataset\n",
    "- splitted into training and test dataset 80%, 20%\n",
    "- for each distance algorith, running k-NN from 1 to 9 and printing its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "from math import * # for math operation\n",
    "from decimal import Decimal # for decimal approximation\n",
    "import operator # for selection\n",
    "import pandas as pd # for handling iris dataset\n",
    "from sklearn.model_selection import train_test_split # for splitting dataset into train/test\n",
    "from sklearn.preprocessing import StandardScaler # for Column Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My test vector\n",
    "\n",
    "v1 = [1.0, 3.2, 4.8, 0.1, 3.2, 0.6, 2.2, 1.1]\n",
    "v2 = [0.1, 5.2, 1.9, 4.2, 1.9, 0.1, 0.1, 6.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Algorthm Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan Distance\n",
    "\n",
    "Also referred as L<sub>1</sup> Norm\n",
    "\n",
    "\\begin{equation*}\n",
    "L_1 Norm = \\lvert \\vert x - y \\rvert \\rvert_1 = \\left( \\sum_{i=1}^n \\lvert (x_i - y_i) \\rvert \\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000 0.000\n",
      "18.700 18.700\n"
     ]
    }
   ],
   "source": [
    "def manhanttan_dist(v1, v2):\n",
    "    '''\n",
    "    returns manhattan distance between vector v1 and v2 having same dimension d\n",
    "    numeric components for vectors v1 and v2 are assumed\n",
    "    '''\n",
    "    return round(Decimal(sum(abs(a-b) for a, b in zip(v1, v2))),3)\n",
    "\n",
    "print(manhanttan_dist(v1,v1), manhanttan_dist(v2,v2))\n",
    "print(manhanttan_dist(v1, v2), manhanttan_dist(v2, v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eucliean Distance\n",
    "\n",
    "Also referred as L<sub>2</sub> Norm\n",
    "\n",
    "\\begin{equation*}\n",
    "L_2 Norm = \\lvert \\vert x - y \\rvert \\rvert_2 = \\sqrt{\\left( \\sum_{i=1}^d (x_{1i} - y_{2i})^2 \\right)} = \\sqrt{(x-y)^T(x-y)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "L_2 Norm = \\lvert \\vert x - y \\rvert \\rvert_2 = \\left( \\sum_{i=1}^d (x_{1i} - y_{2i})^2 \\right)^\\frac{1}{2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucd_dist(v1,v2):\n",
    "    '''\n",
    "    returns euclidean distance between vector v1 and v2 having same dimension d\n",
    "    numeric components for vectors v1 and v2 are assumed\n",
    "    '''\n",
    "    return round(Decimal(sqrt(sum(pow(a-b,2) for a,b in zip(v1,v2)))),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000 0.000\n",
      "7.771 7.771\n"
     ]
    }
   ],
   "source": [
    "print(eucd_dist(v1,v1), eucd_dist(v2,v2))\n",
    "print(eucd_dist(v1, v2), eucd_dist(v2, v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski Distance\n",
    "\n",
    "Also referred as L<sub>p</sub> Norm, where __p > 0__\n",
    "\n",
    "[Can be used for both 'Ordinal' and 'Quantitative' Values](https://people.revoledu.com/kardi/tutorial/Similarity/MinkowskiDistance.html)\n",
    "\n",
    "\\begin{equation*}\n",
    "L_p Norm = \\lvert \\vert x - y \\rvert \\rvert_p = \\left( \\sum_{i=1}^d \\lvert x_{1i} - y_{2i} \\rvert ^p \\right)^\\frac{1}{p}\n",
    "\\end{equation*}\n",
    "\n",
    "Observations of Minkowski:\n",
    "\n",
    "\\begin{equation*}\n",
    "L_1 Norm = Manhattan Distance\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "L_2 Norm = Euclidean Distance\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "L_\\infty Norm = Chebyshev Distance = L_{max} Norm\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p : 1 18.700 18.700\n",
      "p : 2 7.771 7.771\n",
      "p : 3 6.138 6.138\n",
      "p : 4 5.579 5.579\n"
     ]
    }
   ],
   "source": [
    "def getNthRoot(val, n_root):\n",
    "    '''\n",
    "    returns n_th root of the given value\n",
    "    '''\n",
    "    return round(Decimal(val) ** Decimal(Decimal(1.0)/n_root),3)\n",
    "\n",
    "def minkowski_dist(v1, v2, p):\n",
    "    '''\n",
    "    returns minkowski distance between vectors v1 and v2 of same dimension d\n",
    "        numeric components for vectors v1 and v2 are assumed\n",
    "        v1, v2 ==> vectors\n",
    "        p ==> p-form that need to be calcualted\n",
    "    '''\n",
    "    return getNthRoot(sum(pow(abs(a-b),p) for a,b in zip(v1, v2)), p)\n",
    "\n",
    "#print(getNthRoot(2,9))\n",
    "#print(minkowski_dist([0,3,4,5], [7,6,3,-1], 3))\n",
    "\n",
    "\n",
    "for p in range(1,5):\n",
    "    print(\"p :\", p, minkowski_dist(v1, v2, p), minkowski_dist(v2, v1, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consine Similarity\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "\\cos \\theta = \\frac{a.b}{\\lvert \\lvert a \\rvert \\rvert \\; \\lvert  \\lvert b \\rvert \\rvert}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\cos \\theta = \\frac{a^Tb}{\\lvert \\lvert a \\rvert \\rvert \\; \\lvert \\lvert b \\rvert \\rvert}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\cos \\theta = \\Bigl(\\frac{a}{\\lvert \\lvert a \\rvert \\rvert}\\Bigr) ^T \\; \\Bigl(\\frac{b}{\\lvert \\lvert b \\rvert \\rvert}\\Bigr)\n",
    "\\end{equation*}\n",
    "\n",
    "if both a and b are unit vectors, then cosine similarity is the dot product of both vectors a and b\n",
    "\n",
    "\\begin{equation*}\n",
    "\\cos \\theta = a . b\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dot Product (Alebraic Equation)__\n",
    "\n",
    "Let, x = [x1, x2, ..., xd] a vector, y = [y1, y2, ...., yd] a vector\n",
    "\n",
    "the Dot product of x.y is (Algebraic)\n",
    "\n",
    "\\begin{equation*}\n",
    "x.y = x^T y\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x.y = x_1 y_1 + x_2 y_2 + ... + x_d y_d\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "x.y = \\sum_{i=1}^d x_i y_i\n",
    "\\end{equation*}\n",
    "\n",
    "Algebraic Dot Product of two vectors tells how similar those two vectors are. Usefull in Text Processing to find how two vectors are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dot Product (Geometric Equation)__\n",
    "\n",
    "\\begin{equation*}\n",
    "x.y = \\lvert \\lvert x \\rvert \\rvert \\; \\lvert \\lvert y \\rvert \\rvert \\; \\cos \\theta\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "*cosine and euclidean distance are same if the vectors are in unit length*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "- It is a metrix used t measure how similar the documents are irrespective of their size\n",
    "- Mahtematically it measures the cosine of the angle between two vectors projected in a multi-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use Cosine__\n",
    "\n",
    "https://cmry.github.io/notes/euclidean-v-cosine\n",
    "\n",
    "- Cosine Similarity is generally used as a metric for measuring distance when the magnitude of the vectors does not matter. This happens for example when working with text data represented by word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(v1, v2):\n",
    "    '''\n",
    "    returns algebraic dot product of two vectors v1 and v2\n",
    "    '''\n",
    "    return Decimal(sum(a*b for a,b in zip(v1,v2)))\n",
    "\n",
    "def getLength(v1):\n",
    "    '''\n",
    "    returns length/magniture of the given vector\n",
    "    '''\n",
    "    return Decimal(sqrt(sum(x*x for x in v1)))\n",
    "\n",
    "def scalarMultiply(v1, c):\n",
    "    '''\n",
    "    performs scalar multiplication over given vector v1\n",
    "    '''\n",
    "    return [round(Decimal(x*c),3) for x in v1]\n",
    "\n",
    "def normalize(v1):\n",
    "    '''\n",
    "    returns the unit vector of given vector v1\n",
    "    '''\n",
    "    l = getLength(v1)\n",
    "    if(l == 0):\n",
    "        return 0; # TO DO - Raise Exception\n",
    "    \n",
    "    return scalarMultiply(v1,(Decimal(1.0)/l))\n",
    "\n",
    "def cosine_similarity(v1,v2):\n",
    "    '''\n",
    "    returns consine similarity between vectors v1 and v2\n",
    "    '''\n",
    "    numerator = dot_product(v1, v2)\n",
    "    denominator = getLength(v1) * getLength(v2)\n",
    "    return round(Decimal(numerator / denominator), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean_Distance(a,b):  4.123\n",
      "Unit Vecor of a:  [Decimal('0.857'), Decimal('0.514')]\n",
      "Unit Vecor of b:  [Decimal('0.243'), Decimal('0.970')]\n",
      "cos_similarity(a,b):  0.707\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "a = [5,3]\n",
    "b = [1,4]\n",
    "\n",
    "print('Euclidean_Distance(a,b): ', eucd_dist(a,b))\n",
    "print('Unit Vecor of a: ', normalize(a))\n",
    "print('Unit Vecor of b: ', normalize(b))\n",
    "print('cos_similarity(a,b): ', cosine_similarity(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "# https://masongallo.github.io/machine/learning,/python/2016/07/29/cosine-similarity.html\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "# the counts we computed above\n",
    "sentence_m = np.array([1, 1, 1, 1, 0, 0, 0, 0, 0]) \n",
    "sentence_h = np.array([0, 0, 1, 1, 1, 1, 0, 0, 0])\n",
    "sentence_w = np.array([0, 0, 0, 1, 0, 0, 1, 1, 1])\n",
    "\n",
    "# We should expect sentence_m and sentence_h to be more similar\n",
    "print(cos_sim(sentence_m, sentence_h)) # 0.5\n",
    "print(cos_sim(sentence_m, sentence_w)) # 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Dissimlarity\n",
    "\n",
    "\\begin{equation*}\n",
    "1 - cosine\\_similarity(x,y)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consine_dissimilarity(v1, v2):\n",
    "    '''\n",
    "    returns cosine dissimilarity between vectors v1 and v2\n",
    "    '''\n",
    "    return (1-cosine_similarity(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_similarity(a,b):  0.293\n"
     ]
    }
   ],
   "source": [
    "print('cos_similarity(a,b): ', consine_dissimilarity(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Implementation (for Iris DataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./iris.data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data and labels for easy handling\n",
    "# 80% training\n",
    "# 20% for testing\n",
    "df_train, df_test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "#df_data = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "#df_labels = df[['species']]\n",
    "#print(df_data.head())\n",
    "#print(df_labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:\n",
      "(105, 5)\n",
      "     sepal_length  sepal_width  petal_length  petal_width     species\n",
      "85            6.0          3.4           4.5          1.6  versicolor\n",
      "38            4.4          3.0           1.3          0.2      setosa\n",
      "103           6.3          2.9           5.6          1.8   virginica\n",
      "44            5.1          3.8           1.9          0.4      setosa\n",
      "140           6.7          3.1           5.6          2.4   virginica\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    105.000000   105.000000    105.000000   105.000000\n",
      "mean       5.853333     3.014286      3.812381     1.206667\n",
      "std        0.828932     0.415662      1.737798     0.749136\n",
      "min        4.400000     2.000000      1.300000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.400000     1.300000\n",
      "75%        6.400000     3.200000      5.100000     1.800000\n",
      "max        7.900000     4.200000      6.900000     2.500000\n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset:')\n",
    "print(df_train.shape)\n",
    "print(df_train.head())\n",
    "print(df_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset:\n",
      "(45, 5)\n",
      "     sepal_length  sepal_width  petal_length  petal_width     species\n",
      "76            6.8          2.8           4.8          1.4  versicolor\n",
      "53            5.5          2.3           4.0          1.3  versicolor\n",
      "113           5.7          2.5           5.0          2.0   virginica\n",
      "87            6.3          2.3           4.4          1.3  versicolor\n",
      "117           7.7          3.8           6.7          2.2   virginica\n",
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count      45.00000    45.000000     45.000000    45.000000\n",
      "mean        5.82000     3.146667      3.633333     1.180000\n",
      "std         0.83492     0.464465      1.838848     0.803289\n",
      "min         4.30000     2.200000      1.000000     0.100000\n",
      "25%         5.10000     2.900000      1.500000     0.300000\n",
      "50%         5.80000     3.100000      4.200000     1.300000\n",
      "75%         6.40000     3.400000      5.100000     1.900000\n",
      "max         7.70000     4.400000      6.700000     2.500000\n"
     ]
    }
   ],
   "source": [
    "print('Test Dataset:')\n",
    "print(df_test.shape)\n",
    "print(df_test.head())\n",
    "print(df_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(training_data_set, query_point, k, algo='euct', p=3):\n",
    "    '''\n",
    "    returns list having k neighbors to the given query data point\n",
    "    input:\n",
    "        training_data_set: Pandas DataFrame\n",
    "        query_point: Pandas DataSeries\n",
    "        k: Number of Neighbors to calculate\n",
    "        algo: type of distance algorithm to use\n",
    "            euct (euclidean distance default)\n",
    "            maht (manhattan)\n",
    "            mink (minkowski)\n",
    "            coss (cosine similarity)\n",
    "            cods (cosine dissimilarity/ cosine distance)\n",
    "        p: minkowski required p norm (default 3)\n",
    "    Output:\n",
    "        List of nearest data points\n",
    "    '''\n",
    "    distances = [] # list to hold all the neighbors\n",
    "    \n",
    "    # calcualte distance between query_point and every point in data set\n",
    "    # create a list\n",
    "    for x in range(len(training_data_set)):\n",
    "        # stip non-numeric label - in training data\n",
    "        v1 = training_data_set.iloc[x]\n",
    "        v1 = v1[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "        #print(type(v1), v1)\n",
    "        \n",
    "        # stip non-numeric label - in query data\n",
    "        q_v = query_point[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "        if algo == 'maht':\n",
    "            dist = manhanttan_dist(q_v, v1)\n",
    "        elif algo == 'mink':\n",
    "            dist = minkowski_dist(q_v, v1, p)\n",
    "        elif algo == 'coss':\n",
    "            dist = cosine_similarity(q_v, v1)\n",
    "        elif algo == 'cods':\n",
    "            dist = consine_dissimilarity(q_v, v1)\n",
    "        else:\n",
    "            dist = eucd_dist(q_v, v1)\n",
    "        distances.append((dist, training_data_set.iloc[x]))\n",
    "        \n",
    "    # sort the list in ascending order\n",
    "    distances.sort(key=lambda tup:tup[0])\n",
    "    #print(distances)\n",
    "    \n",
    "    # select k nearest neighbors and return it\n",
    "    neighbors = []\n",
    "    for i in range(k):\n",
    "        neighbors.append(distances[i][1])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassLabel(neighbors):\n",
    "    '''\n",
    "    returns the class label having majority vote\n",
    "    Note that it doesn't handle 'Not Sure' case yet\n",
    "    '''\n",
    "    class_votes = {} # dictionary keys are flowers, values are its counts\n",
    "    for x in range(len(neighbors)):\n",
    "        class_label = neighbors[x][-1]\n",
    "        if class_label in class_votes:\n",
    "            class_votes[class_label] += 1\n",
    "        else:\n",
    "            class_votes[class_label] = 1\n",
    "    \n",
    "    response = max(class_votes.items(), key=operator.itemgetter(1))[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Predictions\n",
    "\n",
    "- Try to check accuray for k in range 1 to 9\n",
    "    - Euclidean Distance\n",
    "    - Cosine Similarity\n",
    "    - Manhattan Distance\n",
    "    - L_3 Norm (minkowski distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of k that need to be tried\n",
    "max_k = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 2  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 3  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 4  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 5  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 6  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 7  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 8  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 9  Accuracy:  95.556 , Total correct predictions:  43  out of  45\n",
      "k= 10  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "['Euclidean-Distance', 100.0, 100.0, 97.778, 97.778, 97.778, 97.778, 97.778, 97.778, 95.556, 97.778]\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ecut_dist_results = ['Euclidean-Distance']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k)\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    ecut_dist_results.append(accuracy)\n",
    "    \n",
    "print(ecut_dist_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 2  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 3  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 4  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 5  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 6  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 7  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 8  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 9  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "k= 10  Accuracy:  0.0 , Total correct predictions:  0  out of  45\n",
      "['Cosine-Similarity', 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TO-DO\n",
    "# Standardize the Data\n",
    "#standardized_data = StandardScaler().fit_transform(final_counts.toarray().astype(np.float64)) #, with_mean=False\n",
    "#print('Shape of Standardized data', standardized_data.shape)\n",
    "\n",
    "coss_sim_results = ['Cosine-Similarity']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k, 'coss')\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    coss_sim_results.append(accuracy)\n",
    "    \n",
    "print(coss_sim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  95.556 , Total correct predictions:  43  out of  45\n",
      "k= 2  Accuracy:  95.556 , Total correct predictions:  43  out of  45\n",
      "k= 3  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 4  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 5  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 6  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 7  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 8  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 9  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 10  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "['Cosine-Dissimilarity', 95.556, 95.556, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TO-DO\n",
    "# Standardize the Data\n",
    "#standardized_data = StandardScaler().fit_transform(final_counts.toarray().astype(np.float64)) #, with_mean=False\n",
    "#print('Shape of Standardized data', standardized_data.shape)\n",
    "\n",
    "coss_dissim_results = ['Cosine-Dissimilarity']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k, 'cods')\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    coss_dissim_results.append(accuracy)\n",
    "    \n",
    "print(coss_dissim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 2  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 3  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 4  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 5  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 6  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 7  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 8  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 9  Accuracy:  95.556 , Total correct predictions:  43  out of  45\n",
      "k= 10  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "['Manhattan', 100.0, 100.0, 97.778, 97.778, 97.778, 97.778, 97.778, 97.778, 95.556, 97.778]\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "manhattan_results = ['Manhattan']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k, 'maht')\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    manhattan_results.append(accuracy)\n",
    "    \n",
    "print(manhattan_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski Distance with p=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 2  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 3  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 4  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 5  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 6  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 7  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 8  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 9  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 10  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "['Minkowski p=3', 100.0, 100.0, 97.778, 97.778, 97.778, 100.0, 97.778, 97.778, 97.778, 97.778]\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "minkowsi_results_3 = ['Minkowski p=3']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k, 'mink')\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    minkowsi_results_3.append(accuracy)\n",
    "    \n",
    "print(minkowsi_results_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski Distance with p=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 2  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 3  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 4  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 5  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 6  Accuracy:  100.0 , Total correct predictions:  45  out of  45\n",
      "k= 7  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 8  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 9  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "k= 10  Accuracy:  97.778 , Total correct predictions:  44  out of  45\n",
      "['Minkowski p=4', 100.0, 100.0, 97.778, 97.778, 97.778, 100.0, 97.778, 97.778, 97.778, 97.778]\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "minkowsi_results_4 = ['Minkowski p=4']\n",
    "for k in range(1,max_k):\n",
    "    correct_predictions = 0\n",
    "    for t_index in range(len(df_test)):\n",
    "        test_data_point = df_test.iloc[t_index]\n",
    "        neighbors = getNeighbours(df_train, test_data_point, k, 'mink')\n",
    "        predicted_class = getClassLabel(neighbors)\n",
    "        if predicted_class == test_data_point['species']:\n",
    "            correct_predictions += 1\n",
    "        #print('Predicted: ', predicted_class, ' Actual: ', test_data_point['species'])\n",
    "\n",
    "    accuracy = round((correct_predictions/len(df_test)) * 100,3)\n",
    "    print('k=',k,' Accuracy: ', accuracy,', Total correct predictions: ', correct_predictions, ' out of ', len(df_test))\n",
    "    minkowsi_results_4.append(accuracy)\n",
    "    \n",
    "print(minkowsi_results_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euclidean-Distance</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>95.556</td>\n",
       "      <td>97.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cosine-Similarity</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cosine-Dissimilarity</td>\n",
       "      <td>95.556</td>\n",
       "      <td>95.556</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>95.556</td>\n",
       "      <td>97.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Minkowski p=3</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Minkowski p=4</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>100.000</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "      <td>97.778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Method        1        2        3        4        5        6  \\\n",
       "0    Euclidean-Distance  100.000  100.000   97.778   97.778   97.778   97.778   \n",
       "1     Cosine-Similarity    0.000    0.000    0.000    0.000    0.000    0.000   \n",
       "2  Cosine-Dissimilarity   95.556   95.556  100.000  100.000  100.000  100.000   \n",
       "3             Manhattan  100.000  100.000   97.778   97.778   97.778   97.778   \n",
       "4         Minkowski p=3  100.000  100.000   97.778   97.778   97.778  100.000   \n",
       "5         Minkowski p=4  100.000  100.000   97.778   97.778   97.778  100.000   \n",
       "\n",
       "         7        8        9       10  \n",
       "0   97.778   97.778   95.556   97.778  \n",
       "1    0.000    0.000    0.000    0.000  \n",
       "2  100.000  100.000  100.000  100.000  \n",
       "3   97.778   97.778   95.556   97.778  \n",
       "4   97.778   97.778   97.778   97.778  \n",
       "5   97.778   97.778   97.778   97.778  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['Method']\n",
    "[col_names.append(k) for k in range(1,max_k)]\n",
    "disp_df = pd.DataFrame([ecut_dist_results, coss_sim_results, coss_dissim_results, manhattan_results, minkowsi_results_3,minkowsi_results_4], columns=col_names)\n",
    "disp_df.head(len(disp_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "- Training Data highly influences the prediction accuracy\n",
    "    - if we rerun this test multiple times, you can see differences in accuracy for each test\n",
    "    - High Sample Variability seen (Variance)\n",
    "- Low Bias observered (most prediction matches with actual class)\n",
    "- Cosine Similairy\n",
    "    - almost no correct prediction is expected for this dataset\n",
    "    - Since we are using ordinal values, the magnitude (that is we are using length, which is an ordinal measure) also need to be considered\n",
    "    - but cosine similarity dont consider magnitude, it consideres only angle between vectors\n",
    "    - so we are having almost incorrect predictions\n",
    "- Cosine Dissimilarity\n",
    "    - Yet to understand this observation\n",
    "- on multiple trials, it can be observed that prediction performenece is very good\n",
    "    - but still K is chosen based on above table means, it is a overfitting.\n",
    "    - That is trying to find proper K in K-NN based on test data point. Making test data point indirectly as training data, because it is the deciding factor for K value.\n",
    "        - THis will not perform well with actual unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some plotting of data for more understanding on observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2722b1f0fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how images are classifiable \n",
    "ax = df[df['species'] == 'setosa'].plot.scatter(x='sepal_length', y='sepal_width', c = 'blue', label='setosa')\n",
    "ax = df[df['species'] == 'versicolor'].plot.scatter(x='sepal_length', y='sepal_width', c = 'orange', label='versicolor', ax=ax)\n",
    "ax = df[df['species'] == 'virginica'].plot.scatter(x='sepal_length', y='sepal_width', c = 'green', label='virginica', ax=ax)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2722b50be48>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking how images are classifiable \n",
    "ax = df[df['species'] == 'setosa'].plot.scatter(x='petal_length', y='petal_width', c = 'blue', label='setosa')\n",
    "ax = df[df['species'] == 'versicolor'].plot.scatter(x='petal_length', y='petal_width', c = 'orange', label='versicolor', ax=ax)\n",
    "ax = df[df['species'] == 'virginica'].plot.scatter(x='petal_length', y='petal_width', c = 'green', label='virginica', ax=ax)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
